<!DOCTYPE html>
<html lang="pt-BR">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no" />
    <title>AR - Marcador Customizado</title>

    <!-- ✅ Versões COMPATÍVEIS -->
    <script src="https://aframe.io/releases/1.2.0/aframe.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/AR-js-org/AR.js/aframe/build/aframe-ar.js"></script>

    <style>
      * { margin: 0; padding: 0; box-sizing: border-box; }
      html, body { width: 100%; height: 100%; font-family: Arial, sans-serif; }
      body { background: #000; color: #0f0; overflow: hidden; }
      a-scene { width: 100%; height: 100%; }

      #status {
        position: fixed;
        top: 15px;
        left: 15px;
        background: rgba(0, 0, 0, 0.8);
        color: #0f0;
        border: 2px solid #0f0;
        padding: 20px;
        font-family: monospace;
        font-size: 14px;
        z-index: 1000;
        line-height: 1.6;
        min-width: 280px;
      }
      .ok { color: #0f0; font-weight: bold; }
      .erro { color: #f00; font-weight: bold; }
      .warn { color: #ff0; }

      #detectado {
        position: fixed;
        top: 50%;
        left: 50%;
        transform: translate(-50%, -50%);
        background: rgba(0, 200, 0, 0.9);
        color: #fff;
        padding: 40px 80px;
        font-size: 36px;
        font-weight: bold;
        border: 4px solid #0f0;
        border-radius: 20px;
        z-index: 999;
        display: none;
        text-align: center;
      }
      #detectado.ativo {
        display: block;
        animation: pulse 0.5s;
      }
      @keyframes pulse {
        0% { transform: translate(-50%, -50%) scale(1); }
        50% { transform: translate(-50%, -50%) scale(1.1); }
        100% { transform: translate(-50%, -50%) scale(1); }
      }

      #instrucoes {
        position: fixed;
        bottom: 20px;
        left: 50%;
        transform: translateX(-50%);
        background: rgba(0, 0, 0, 0.9);
        color: #0ff;
        border: 2px solid #0ff;
        padding: 20px;
        text-align: center;
        font-size: 14px;
        max-width: 90%;
        z-index: 998;
      }
      /* botão discreto para reproduzir fala se autoplay for bloqueado */
      #btn-play-fala {
        position: fixed;
        right: 18px;
        bottom: 18px;
        z-index: 1001;
        background: #0a84ff;
        color: #fff;
        border: none;
        padding: 10px 14px;
        border-radius: 10px;
        font-weight: bold;
        box-shadow: 0 4px 10px rgba(0,0,0,0.4);
        cursor: pointer;
        display: none; /* mostrado apenas se necessário */
      }
      #btn-play-fala:active { transform: translateY(1px); }

      /* Painel de upload (GLB + áudio opcional) */
      #uploader {
        position: fixed;
        right: 18px;
        top: 18px;
        z-index: 1002;
        background: rgba(0,0,0,0.85);
        border: 1px solid #0ff;
        border-radius: 10px;
        padding: 10px 12px;
        color: #0ff;
        font-size: 12px;
        max-width: 260px;
      }
      #uploader label { display: block; margin: 6px 0 2px; }
      #uploader input[type="file"] {
        width: 100%;
        color: #0ff;
      }
    </style>
  </head>

  <body>
    <div id="status">
      <strong>STATUS AR</strong><br>
      Camara: <span id="cam" class="warn">⟳</span><br>
      A-Frame: <span id="af" class="warn">⟳</span><br>
      AR.js: <span id="ar" class="warn">⟳</span><br>
      Marcador: <span id="marker" class="erro">⟳ Procurando</span><br><br>
      <small id="msg">Inicializando...</small>
    </div>

    <div id="detectado">✓ MARCADOR DETECTADO!</div>

    <div id="instrucoes">
      <strong>Aponte a câmera para o marcador</strong><br>
      <a href="pattern-marker.patt" download>Baixar marcador</a>
    </div>

    <!-- Painel para envio de modelo GLB e áudio opcional -->
    <div id="uploader" aria-label="Enviar modelo e áudio">
      <strong>Carregar Conteúdo</strong>
      <label for="glbInput">Modelo (.glb)</label>
      <input id="glbInput" type="file" accept=".glb">
      <label for="audioInput">Áudio (opcional)</label>
      <input id="audioInput" type="file" accept="audio/*">
      <small>O áudio toca após clicar em "Ouvir fala".</small>
    </div>

    <!-- Botão de fallback para iniciar a fala caso o navegador bloqueie autoplay -->
    <button id="btn-play-fala" aria-label="Ouvir fala">Ouvir fala</button>

    <!-- ✅ Cena AR configurada corretamente ✅ -->
    <a-scene
      embedded
      vr-mode-ui="enabled: false"
      arjs="trackingMethod: best; sourceType: webcam; debugUIEnabled: false;"
      renderer="logarithmicDepthBuffer: true;"
    >
      <a-assets>
        <a-asset-item id="model" src="model1.glb"></a-asset-item>
      </a-assets>

      <!-- ✅ Marcador com eventos funcionando -->
      <a-marker
        type="pattern"
        url="pattern-marker.patt"
        emitevents="true"
        id="meu-marker"
      >
        <!--
          `id="modelo-personagem"` -> facilita selecionar o modelo via JS
          `rotating-when-visible` -> componente custom que gira suavemente quando ativo
          `character-speech` -> componente custom para tocar áudio e preparar sincronização labial
        -->
        <a-gltf-model
          id="modelo-personagem"
          src="#model"
          position="0 0 0"
          scale="0.4 0.4 0.4"
          rotation="0 0 0"
          rotating-when-visible="speed: 15"
          character-speech="audioSelector: #fala1"
        ></a-gltf-model>
      </a-marker>

      <a-entity camera></a-entity>
    </a-scene>

      <!-- Áudio da personagem (pré-carregado).
        Coloque o arquivo `audio1.m4a` na mesma pasta do projeto. -->
      <audio id="fala1" src="audio1.m4a" preload="auto"></audio>

    <script>
      console.clear();
      console.log("=== AR INICIADO ===");

      document.getElementById("cam").textContent = "✓";
      document.getElementById("cam").className = "ok";

      document.addEventListener('DOMContentLoaded', () => {
        document.getElementById("af").textContent = "✓";
        document.getElementById("af").className = "ok";
        document.getElementById("ar").textContent = "✓";
        document.getElementById("ar").className = "ok";
      });

      // ✅ Eventos oficiais de AR.js
      const marker = document.getElementById("meu-marker");

      // Registramos dois componentes customizados abaixo:
      // 1) rotating-when-visible: roda o modelo no eixo Y enquanto ativo (deg/s)
      // 2) character-speech: toca um áudio e expõe método para sincronizar boca no futuro

      /* Componente: rotating-when-visible
         - data.speed: graus por segundo (default 15)
         - expõe métodos `start()` e `stop()` para controlar rotação externamente
         - usa tick() para atualização suave baseada em timeDelta (compatível A-Frame 1.2.0)
      */
      AFRAME.registerComponent('rotating-when-visible', {
        schema: { speed: { type: 'number', default: 15 } },
        init: function () {
          this.isRotating = false;
          // start/stop expostos para chamadas externas (ex.: markerFound/markerLost)
          this.start = () => { this.isRotating = true; };
          this.stop = () => { this.isRotating = false; };
        },
        tick: function (time, timeDelta) {
          // timeDelta em ms; converte para segundos
          if (!this.isRotating) return;
          const rot = this.el.getAttribute('rotation') || { x: 0, y: 0, z: 0 };
          // incrementa Y de forma suave: speed (deg/s) * dt
          rot.y = (rot.y + this.data.speed * (timeDelta / 1000)) % 360;
          this.el.setAttribute('rotation', rot);
        },
        remove: function () { this.isRotating = false; }
      });

      /* Componente: character-speech
         - data.audioSelector: seletor do elemento <audio> (default '#fala1')
         - fornece método `playSpeech()` para iniciar a fala
         - fornece método `stopSpeech()` para interromper
         - expõe `syncMouth()` placeholder para futura sincronização labial
      */
      AFRAME.registerComponent('character-speech', {
        schema: { audioSelector: { type: 'selector', default: '#fala1' } },
        init: function () {
          // A-Frame com schema selector já retorna o elemento se existir
          this.audioEl = this.data.audioSelector || document.querySelector('#fala1');
          this.isPlaying = false;

          // Handler que será chamado em cada update do áudio para futura sincronização
          this._onTimeUpdate = (ev) => {
            // Atualmente chamamos syncMouth como placeholder
            // TODO: implementar animação labial aqui (usar ev.currentTime para sincronizar)
            this.syncMouth(ev);
          };

          if (this.audioEl) {
            this.audioEl.addEventListener('timeupdate', this._onTimeUpdate);
          } else {
            console.warn('[character-speech] áudio não encontrado para selector', this.data.audioSelector);
          }

          // métodos públicos
          this.playSpeech = () => {
            if (!this.audioEl) { console.warn('[character-speech] áudio ausente'); return; }
            try {
              // Reinicia e tenta tocar. Note: navegadores podem bloquear autoplay sem interação do usuário.
              this.audioEl.currentTime = 0;
              const p = this.audioEl.play();
              if (p && p.then) {
                p.then(() => {
                  this.isPlaying = true;
                  // Se a reprodução começou com sucesso, garante que o botão de fallback fique oculto
                  const btn = document.getElementById('btn-play-fala');
                  if (btn) btn.style.display = 'none';
                }).catch(err => {
                  console.warn('play() falhou:', err);
                  // Mostra um botão para que o usuário permita reprodução manualmente
                  const btn = document.getElementById('btn-play-fala');
                  if (btn) btn.style.display = 'block';
                });
              } else {
                this.isPlaying = true;
              }
            } catch (e) {
              console.warn('[character-speech] erro ao tocar áudio', e);
              const btn = document.getElementById('btn-play-fala');
              if (btn) btn.style.display = 'block';
            }
          };

          this.stopSpeech = () => {
            if (!this.audioEl) return;
            this.audioEl.pause();
            this.audioEl.currentTime = 0;
            this.isPlaying = false;
          };

          // Placeholder público para futuras implementações de sincronização labial
          this.syncMouth = (audioEventOrTime) => {
            // TODO: usar audioEventOrTime.currentTime ou valor numérico para animar a boca do personagem
            // Exemplo futuro: extrair volume ou usar WebAudio API para visemes.
          };
        },
        remove: function () {
          if (this.audioEl) this.audioEl.removeEventListener('timeupdate', this._onTimeUpdate);
        }
      });

      // Agora usamos os eventos do marcador para ativar/desativar comportamentos
      marker.addEventListener('markerFound', () => {
        console.log('⭐ Marcador detectado!');
        document.getElementById('marker').textContent = '✓ DETECTADO';
        document.getElementById('marker').className = 'ok';
        document.getElementById('detectado').classList.add('ativo');
        document.getElementById('msg').textContent = '✓ Modelo Carregado!';

        // Seleciona o modelo e inicia rotação.
        // A fala NÃO será iniciada automaticamente — o usuário deverá pressionar o botão após o retângulo desaparecer.
        const modelEl = document.getElementById('modelo-personagem');
        if (modelEl) {
          // Se o componente de rotação já estiver inicializado, usa seu método start()
          const rotComp = modelEl.components['rotating-when-visible'];
          if (rotComp && rotComp.start) {
            rotComp.start();
          } else {
            // Garante que o componente exista (caso não tenha sido inicializado ainda)
            modelEl.setAttribute('rotating-when-visible', '');
            // Tenta novamente após pequeno delay para garantir inicialização
            setTimeout(() => {
              const r = modelEl.components['rotating-when-visible'];
              if (r && r.start) r.start();
            }, 50);
          }
        }

        // Após 2 segundos removemos o retângulo verde da tela e mostramos o botão "Ouvir fala"
        // Isso evita sobreposição visual e segue o pedido do usuário: permitir que o usuário pressione Play
        setTimeout(() => {
          const detectEl = document.getElementById('detectado');
          if (detectEl) detectEl.classList.remove('ativo');
          const btn = document.getElementById('btn-play-fala');
          if (btn) btn.style.display = 'block';
        }, 2000);
      });

      marker.addEventListener('markerLost', () => {
        console.log('Marcador perdido');
        document.getElementById('marker').textContent = '⟳ Procurando';
        document.getElementById('marker').className = 'erro';
        document.getElementById('detectado').classList.remove('ativo');
        document.getElementById('msg').textContent = 'Procurando marcador...';

        // Para rotação e fala quando marcador é perdido
        const modelEl = document.getElementById('modelo-personagem');
        if (modelEl) {
          const rotComp = modelEl.components['rotating-when-visible'];
          if (rotComp && rotComp.stop) rotComp.stop();

          const speechComp = modelEl.components['character-speech'];
          if (speechComp && speechComp.stopSpeech) speechComp.stopSpeech();
        }
        // Esconde o botão de play quando o marcador some
        const btn = document.getElementById('btn-play-fala');
        if (btn) btn.style.display = 'none';
      });

      // --- Fallback UI: botão para tocar fala manualmente (se autoplay bloqueado) ---
      const btnPlayFala = document.getElementById('btn-play-fala');
      if (btnPlayFala) {
        btnPlayFala.addEventListener('click', () => {
          // Tenta acionar a fala no modelo (se o componente estiver disponível)
          const modelEl = document.getElementById('modelo-personagem');
          if (modelEl) {
            const speechComp = modelEl.components['character-speech'];
            if (speechComp && speechComp.playSpeech) {
              speechComp.playSpeech();
              // Oculta o botão após o clique
              btnPlayFala.style.display = 'none';
            } else {
              // Caso o componente ainda não esteja pronto, inicializa e tenta novamente
              modelEl.setAttribute('character-speech', '');
              setTimeout(() => {
                const s = modelEl.components['character-speech'];
                if (s && s.playSpeech) s.playSpeech();
                btnPlayFala.style.display = 'none';
              }, 100);
            }
          } else {
            // Se não há modelo, tenta tocar o elemento <audio> diretamente como fallback
            const audio = document.getElementById('fala1');
            if (audio) {
              audio.play().catch(err => console.warn('Erro ao tocar áudio diretamente:', err));
              btnPlayFala.style.display = 'none';
            }
          }
        });
      }

      // --- Upload de GLB e Áudio (opcional) ---
      (function setupUploads(){
        const glbInput = document.getElementById('glbInput');
        const audioInput = document.getElementById('audioInput');
        const modelEl = document.getElementById('modelo-personagem');
        const audioEl = document.getElementById('fala1');
        const msgEl = document.getElementById('msg');
        let currentModelBlobUrl = null;
        let currentAudioBlobUrl = null;

        if (glbInput && modelEl) {
          glbInput.addEventListener('change', (ev) => {
            const file = ev.target.files && ev.target.files[0];
            if (!file) return;
            const name = (file.name || '').toLowerCase();
            if (!name.endsWith('.glb')) {
              console.warn('Arquivo selecionado não é .glb');
              if (msgEl) msgEl.textContent = 'Arquivo inválido. Selecione um .glb';
              return;
            }
            try {
              // Revoga URL anterior, se houver
              if (currentModelBlobUrl) URL.revokeObjectURL(currentModelBlobUrl);
              currentModelBlobUrl = URL.createObjectURL(file);
              // Atualiza fonte do modelo diretamente com a Blob URL
              modelEl.setAttribute('src', currentModelBlobUrl);
              if (msgEl) msgEl.textContent = '✓ Modelo (.glb) carregado';
            } catch (e) {
              console.warn('Falha ao carregar GLB:', e);
              if (msgEl) msgEl.textContent = 'Falha ao carregar GLB';
            }
          });
        }

        if (audioInput && audioEl) {
          audioInput.addEventListener('change', (ev) => {
            const file = ev.target.files && ev.target.files[0];
            if (!file) return;
            try {
              if (currentAudioBlobUrl) URL.revokeObjectURL(currentAudioBlobUrl);
              currentAudioBlobUrl = URL.createObjectURL(file);
              audioEl.pause();
              audioEl.src = currentAudioBlobUrl;
              audioEl.load();
              if (msgEl) msgEl.textContent = '✓ Áudio carregado (use "Ouvir fala")';
              // Mostra botão para o usuário iniciar a reprodução quando quiser
              const btn = document.getElementById('btn-play-fala');
              if (btn) btn.style.display = 'block';
            } catch (e) {
              console.warn('Falha ao carregar áudio:', e);
              if (msgEl) msgEl.textContent = 'Falha ao carregar áudio';
            }
          });
        }
      })();
    </script>
  </body>
</html>
